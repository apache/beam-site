

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>apache_beam.ml.inference.huggingface_inference module &mdash; Apache Beam 2.60.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/documentation_options.js?v=1bc0be70"></script>
      <script src="_static/doctools.js?v=9a2dae69"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="apache_beam.ml.inference.onnx_inference module" href="apache_beam.ml.inference.onnx_inference.html" />
    <link rel="prev" title="apache_beam.ml.inference.base module" href="apache_beam.ml.inference.base.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Apache Beam
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="apache_beam.coders.html">apache_beam.coders package</a></li>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.dataframe.html">apache_beam.dataframe package</a></li>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.io.html">apache_beam.io package</a></li>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.metrics.html">apache_beam.metrics package</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="apache_beam.ml.html">apache_beam.ml package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="apache_beam.ml.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="apache_beam.ml.gcp.html">apache_beam.ml.gcp package</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="apache_beam.ml.inference.html">apache_beam.ml.inference package</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="apache_beam.ml.inference.html#submodules">Submodules</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache_beam.ml.transforms.html">apache_beam.ml.transforms package</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.options.html">apache_beam.options package</a></li>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.portability.html">apache_beam.portability package</a></li>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.runners.html">apache_beam.runners package</a></li>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.testing.html">apache_beam.testing package</a></li>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.transforms.html">apache_beam.transforms package</a></li>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.typehints.html">apache_beam.typehints package</a></li>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.utils.html">apache_beam.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.yaml.html">apache_beam.yaml package</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.error.html">apache_beam.error module</a></li>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.pipeline.html">apache_beam.pipeline module</a></li>
<li class="toctree-l1"><a class="reference internal" href="apache_beam.pvalue.html">apache_beam.pvalue module</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Apache Beam</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="apache_beam.ml.html">apache_beam.ml package</a></li>
          <li class="breadcrumb-item"><a href="apache_beam.ml.inference.html">apache_beam.ml.inference package</a></li>
      <li class="breadcrumb-item active">apache_beam.ml.inference.huggingface_inference module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/apache_beam.ml.inference.huggingface_inference.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-apache_beam.ml.inference.huggingface_inference">
<span id="apache-beam-ml-inference-huggingface-inference-module"></span><h1>apache_beam.ml.inference.huggingface_inference module<a class="headerlink" href="#module-apache_beam.ml.inference.huggingface_inference" title="Link to this heading">Â¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">apache_beam.ml.inference.huggingface_inference.</span></span><span class="sig-name descname"><span class="pre">HuggingFaceModelHandlerTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_uri</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_class</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">transformers.AutoModel</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">transformers.TFAutoModel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'CPU'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inference_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Iterable" title="(in Python v3.13)"><span class="pre">Iterable</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.PredictionResult" title="apache_beam.ml.inference.base.PredictionResult"><span class="pre">PredictionResult</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_model_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batch_duration_secs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">large_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_copies</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.ModelHandler" title="apache_beam.ml.inference.base.ModelHandler"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelHandler</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> | <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <a class="reference internal" href="apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.PredictionResult" title="apache_beam.ml.inference.base.PredictionResult"><code class="xref py py-class docutils literal notranslate"><span class="pre">PredictionResult</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">AutoModel</span></code> | <code class="xref py py-class docutils literal notranslate"><span class="pre">TFAutoModel</span></code>]</p>
<p>Implementation of the ModelHandler interface for HuggingFace with
Tensors for PyTorch/Tensorflow backend.</p>
<p>Depending on the type of tensors, the model framework is determined
automatically.</p>
<dl class="simple">
<dt>Example Usage model:</dt><dd><dl class="simple">
<dt>pcoll | RunInference(HuggingFaceModelHandlerTensor(</dt><dd><p>model_uri=âbert-base-uncasedâ, model_class=AutoModelForMaskedLM))</p>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_uri</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) â path to the pretrained model on the hugging face
models hub.</p></li>
<li><p><strong>model_class</strong> â model class to load the repository from model_uri.</p></li>
<li><p><strong>device</strong> â For torch tensors, specify device on which you wish to
run the model. Defaults to CPU.</p></li>
<li><p><strong>inference_fn</strong> â the inference function to use during RunInference.
Default is _run_inference_torch_keyed_tensor or
_run_inference_tensorflow_keyed_tensor depending on the input type.</p></li>
<li><p><strong>load_model_args</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>Any</em><em>]</em>) â (Optional) keyword arguments to provide
load options while loading models from Hugging Face Hub.
Defaults to None.</p></li>
<li><p><strong>min_batch_size</strong> â the minimum batch size to use when batching inputs.</p></li>
<li><p><strong>max_batch_size</strong> â the maximum batch size to use when batching inputs.</p></li>
<li><p><strong>max_batch_duration_secs</strong> â the maximum amount of time to buffer a batch
before emitting; used in streaming contexts.</p></li>
<li><p><strong>large_model</strong> â set to true if your model is large enough to run into
memory pressure if you load multiple copies. Given a model that
consumes N memory and a machine with W cores and M memory, you should
set this to True if N*W &gt; M.</p></li>
<li><p><strong>model_copies</strong> â The exact number of models that you would like loaded
onto your machine. This can be useful if you exactly know your CPU or
GPU capacity and want to maximize resource utilization.</p></li>
<li><p><strong>kwargs</strong> â âenv_varsâ can be used to set environment variables
before loading the model.</p></li>
</ul>
</dd>
</dl>
<p><strong>Supported Versions:</strong> HuggingFaceModelHandler supports
transformers&gt;=4.18.0.</p>
<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerTensor.load_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.load_model" title="Link to this definition">Â¶</a></dt>
<dd><p>Loads and initializes the model for processing.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.run_inference">
<span class="sig-name descname"><span class="pre">run_inference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(in Python v3.13)"><span class="pre">Sequence</span></a><span class="p"><span class="pre">[</span></span><span class="pre">tensorflow.Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">transformers.AutoModel</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">transformers.TFAutoModel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inference_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Iterable" title="(in Python v3.13)"><span class="pre">Iterable</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.PredictionResult" title="apache_beam.ml.inference.base.PredictionResult"><span class="pre">PredictionResult</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerTensor.run_inference"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.run_inference" title="Link to this definition">Â¶</a></dt>
<dd><p>Runs inferences on a batch of Tensors and returns an Iterable of
Tensors Predictions.</p>
<p>This method stacks the list of Tensors in a vectorized format to optimize
the inference call.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> â A sequence of Tensors. These Tensors should be batchable, as
this method will call <cite>tf.stack()</cite>/<cite>torch.stack()</cite> and pass in
batched Tensors with dimensions (batch_size, n_features, etc.)
into the modelâs predict() function.</p></li>
<li><p><strong>model</strong> â A Tensorflow/PyTorch model.</p></li>
<li><p><strong>inference_args</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>Any</em><em>]</em>) â Non-batchable arguments required as
inputs to the modelâs inference function. Unlike Tensors in <cite>batch</cite>,
these parameters will not be dynamically batched.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An Iterable of type PredictionResult.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.update_model_path">
<span class="sig-name descname"><span class="pre">update_model_path</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerTensor.update_model_path"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.update_model_path" title="Link to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.get_num_bytes">
<span class="sig-name descname"><span class="pre">get_num_bytes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(in Python v3.13)"><span class="pre">Sequence</span></a><span class="p"><span class="pre">[</span></span><span class="pre">tensorflow.Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerTensor.get_num_bytes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.get_num_bytes" title="Link to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The number of bytes of data for the Tensors batch.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.batch_elements_kwargs">
<span class="sig-name descname"><span class="pre">batch_elements_kwargs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerTensor.batch_elements_kwargs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.batch_elements_kwargs" title="Link to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.share_model_across_processes">
<span class="sig-name descname"><span class="pre">share_model_across_processes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerTensor.share_model_across_processes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.share_model_across_processes" title="Link to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.model_copies">
<span class="sig-name descname"><span class="pre">model_copies</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerTensor.model_copies"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.model_copies" title="Link to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.get_metrics_namespace">
<span class="sig-name descname"><span class="pre">get_metrics_namespace</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerTensor.get_metrics_namespace"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerTensor.get_metrics_namespace" title="Link to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A namespace for metrics collected by the RunInference transform.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">apache_beam.ml.inference.huggingface_inference.</span></span><span class="sig-name descname"><span class="pre">HuggingFaceModelHandlerKeyedTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_uri</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_class</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">transformers.AutoModel</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">transformers.TFAutoModel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">framework</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'CPU'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inference_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><span class="pre">Callable</span></a><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Iterable" title="(in Python v3.13)"><span class="pre">Iterable</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.PredictionResult" title="apache_beam.ml.inference.base.PredictionResult"><span class="pre">PredictionResult</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_model_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batch_duration_secs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">large_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_copies</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerKeyedTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.ModelHandler" title="apache_beam.ml.inference.base.ModelHandler"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelHandler</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> | <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>], <a class="reference internal" href="apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.PredictionResult" title="apache_beam.ml.inference.base.PredictionResult"><code class="xref py py-class docutils literal notranslate"><span class="pre">PredictionResult</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">AutoModel</span></code> | <code class="xref py py-class docutils literal notranslate"><span class="pre">TFAutoModel</span></code>]</p>
<p>Implementation of the ModelHandler interface for HuggingFace with
Keyed Tensors for PyTorch/Tensorflow backend.</p>
<dl class="simple">
<dt>Example Usage model::</dt><dd><dl class="simple">
<dt>pcoll | RunInference(HuggingFaceModelHandlerKeyedTensor(</dt><dd><p>model_uri=âbert-base-uncasedâ, model_class=AutoModelForMaskedLM,
framework=âptâ))</p>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_uri</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) â path to the pretrained model on the hugging face
models hub.</p></li>
<li><p><strong>model_class</strong> â model class to load the repository from model_uri.</p></li>
<li><p><strong>framework</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) â Framework to use for the model. âtfâ for TensorFlow and
âptâ for PyTorch.</p></li>
<li><p><strong>device</strong> â For torch tensors, specify device on which you wish to
run the model. Defaults to CPU.</p></li>
<li><p><strong>inference_fn</strong> â the inference function to use during RunInference.
Default is _run_inference_torch_keyed_tensor or
_run_inference_tensorflow_keyed_tensor depending on the input type.</p></li>
<li><p><strong>load_model_args</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>Any</em><em>]</em>) â (Optional) Keyword arguments to provide
load options while loading models from Hugging Face Hub.
Defaults to None.</p></li>
<li><p><strong>min_batch_size</strong> â the minimum batch size to use when batching inputs.</p></li>
<li><p><strong>max_batch_size</strong> â the maximum batch size to use when batching inputs.</p></li>
<li><p><strong>max_batch_duration_secs</strong> â the maximum amount of time to buffer a batch
before emitting; used in streaming contexts.</p></li>
<li><p><strong>large_model</strong> â set to true if your model is large enough to run into
memory pressure if you load multiple copies. Given a model that
consumes N memory and a machine with W cores and M memory, you should
set this to True if N*W &gt; M.</p></li>
<li><p><strong>model_copies</strong> â The exact number of models that you would like loaded
onto your machine. This can be useful if you exactly know your CPU or
GPU capacity and want to maximize resource utilization.</p></li>
<li><p><strong>kwargs</strong> â âenv_varsâ can be used to set environment variables
before loading the model.</p></li>
</ul>
</dd>
</dl>
<p><strong>Supported Versions:</strong> HuggingFaceModelHandler supports
transformers&gt;=4.18.0.</p>
<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerKeyedTensor.load_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.load_model" title="Link to this definition">Â¶</a></dt>
<dd><p>Loads and initializes the model for processing.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.run_inference">
<span class="sig-name descname"><span class="pre">run_inference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(in Python v3.13)"><span class="pre">Sequence</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tensorflow.Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">transformers.AutoModel</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">transformers.TFAutoModel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inference_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Iterable" title="(in Python v3.13)"><span class="pre">Iterable</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.PredictionResult" title="apache_beam.ml.inference.base.PredictionResult"><span class="pre">PredictionResult</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerKeyedTensor.run_inference"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.run_inference" title="Link to this definition">Â¶</a></dt>
<dd><p>Runs inferences on a batch of Keyed Tensors and returns an Iterable of
Tensors Predictions.</p>
<p>This method stacks the list of Tensors in a vectorized format to optimize
the inference call.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> â A sequence of Keyed Tensors. These Tensors should be batchable,
as this method will call <cite>tf.stack()</cite>/<cite>torch.stack()</cite> and pass in
batched Tensors with dimensions (batch_size, n_features, etc.) into
the modelâs predict() function.</p></li>
<li><p><strong>model</strong> â A Tensorflow/PyTorch model.</p></li>
<li><p><strong>inference_args</strong> â Non-batchable arguments required as inputs to the
modelâs inference function. Unlike Tensors in <cite>batch</cite>,
these parameters will not be dynamically batched.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An Iterable of type PredictionResult.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.update_model_path">
<span class="sig-name descname"><span class="pre">update_model_path</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerKeyedTensor.update_model_path"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.update_model_path" title="Link to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.get_num_bytes">
<span class="sig-name descname"><span class="pre">get_num_bytes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(in Python v3.13)"><span class="pre">Sequence</span></a><span class="p"><span class="pre">[</span></span><span class="pre">tensorflow.Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerKeyedTensor.get_num_bytes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.get_num_bytes" title="Link to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The number of bytes of data for the Tensors batch.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.batch_elements_kwargs">
<span class="sig-name descname"><span class="pre">batch_elements_kwargs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerKeyedTensor.batch_elements_kwargs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.batch_elements_kwargs" title="Link to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.share_model_across_processes">
<span class="sig-name descname"><span class="pre">share_model_across_processes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerKeyedTensor.share_model_across_processes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.share_model_across_processes" title="Link to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.model_copies">
<span class="sig-name descname"><span class="pre">model_copies</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerKeyedTensor.model_copies"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.model_copies" title="Link to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.get_metrics_namespace">
<span class="sig-name descname"><span class="pre">get_metrics_namespace</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFaceModelHandlerKeyedTensor.get_metrics_namespace"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFaceModelHandlerKeyedTensor.get_metrics_namespace" title="Link to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A namespace for metrics collected by the RunInference transform.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">apache_beam.ml.inference.huggingface_inference.</span></span><span class="sig-name descname"><span class="pre">HuggingFacePipelineModelHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">task:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">~apache_beam.ml.inference.huggingface_inference.PipelineTask</span> <span class="pre">=</span> <span class="pre">'',</span> <span class="pre">model:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'',</span> <span class="pre">*,</span> <span class="pre">device:</span> <span class="pre">str</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">inference_fn:</span> <span class="pre">~typing.Callable[[~typing.Sequence[str],</span> <span class="pre">transformers.Pipeline,</span> <span class="pre">~typing.Dict[str,</span> <span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None],</span> <span class="pre">~typing.Iterable[~apache_beam.ml.inference.base.PredictionResult]]</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">_default_pipeline_inference_fn&gt;,</span> <span class="pre">load_pipeline_args:</span> <span class="pre">~typing.Dict[str,</span> <span class="pre">~typing.Any]</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">min_batch_size:</span> <span class="pre">int</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">max_batch_size:</span> <span class="pre">int</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">max_batch_duration_secs:</span> <span class="pre">int</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">large_model:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False,</span> <span class="pre">model_copies:</span> <span class="pre">int</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">**kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFacePipelineModelHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.ModelHandler" title="apache_beam.ml.inference.base.ModelHandler"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelHandler</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference internal" href="apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.PredictionResult" title="apache_beam.ml.inference.base.PredictionResult"><code class="xref py py-class docutils literal notranslate"><span class="pre">PredictionResult</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>]</p>
<p>Implementation of the ModelHandler interface for Hugging Face Pipelines.</p>
<dl class="simple">
<dt>Example Usage model::</dt><dd><dl class="simple">
<dt>pcoll | RunInference(HuggingFacePipelineModelHandler(</dt><dd><p>task=âfill-maskâ))</p>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/enum.html#enum.Enum" title="(in Python v3.13)"><em>enum.Enum</em></a>) â task supported by HuggingFace Pipelines.
Accepts a string task or an enum.Enum from PipelineTask.</p></li>
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) â <p>path to the pretrained <em>model-id</em> on Hugging Face Models Hub
to use custom model for the chosen task. If the <cite>model</cite> already defines
the task then no need to specify the <cite>task</cite> parameter.
Use the <em>model-id</em> string instead of an actual model here.
Model-specific kwargs for <cite>from_pretrained(â¦, **model_kwargs)</cite> can be
specified with <cite>model_kwargs</cite> using <cite>load_pipeline_args</cite>.</p>
<dl class="simple">
<dt>Example Usage::</dt><dd><dl class="simple">
<dt>model_handler = HuggingFacePipelineModelHandler(</dt><dd><p>task=âtext-generationâ, model=âmeta-llama/Llama-2-7b-hfâ,
load_pipeline_args={âmodel_kwargsâ:{âquantization_mapâ:config}})</p>
</dd>
</dl>
</dd>
</dl>
</p></li>
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) â the device (<cite>âCPUâ</cite> or <cite>âGPUâ</cite>) on which you wish to run
the pipeline. Defaults to GPU. If GPU is not available then it falls
back to CPU. You can also use advanced option like <cite>device_map</cite> with
key-value pair as you would do in the usual Hugging Face pipeline using
<cite>load_pipeline_args</cite>. Ex: load_pipeline_args={âdevice_mapâ:auto}).</p></li>
<li><p><strong>inference_fn</strong> â the inference function to use during RunInference.
Default is _default_pipeline_inference_fn.</p></li>
<li><p><strong>load_pipeline_args</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>Any</em><em>]</em>) â keyword arguments to provide load
options while loading pipelines from Hugging Face. Defaults to None.</p></li>
<li><p><strong>min_batch_size</strong> â the minimum batch size to use when batching inputs.</p></li>
<li><p><strong>max_batch_size</strong> â the maximum batch size to use when batching inputs.</p></li>
<li><p><strong>max_batch_duration_secs</strong> â the maximum amount of time to buffer a batch
before emitting; used in streaming contexts.</p></li>
<li><p><strong>large_model</strong> â set to true if your model is large enough to run into
memory pressure if you load multiple copies. Given a model that
consumes N memory and a machine with W cores and M memory, you should
set this to True if N*W &gt; M.</p></li>
<li><p><strong>model_copies</strong> â The exact number of models that you would like loaded
onto your machine. This can be useful if you exactly know your CPU or
GPU capacity and want to maximize resource utilization.</p></li>
<li><p><strong>kwargs</strong> â âenv_varsâ can be used to set environment variables
before loading the model.</p></li>
</ul>
</dd>
</dl>
<p><strong>Supported Versions:</strong> HuggingFacePipelineModelHandler supports
transformers&gt;=4.18.0.</p>
<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFacePipelineModelHandler.load_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.load_model" title="Link to this definition">Â¶</a></dt>
<dd><p>Loads and initializes the pipeline for processing.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.run_inference">
<span class="sig-name descname"><span class="pre">run_inference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(in Python v3.13)"><span class="pre">Sequence</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pipeline</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">transformers.Pipeline</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inference_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Iterable" title="(in Python v3.13)"><span class="pre">Iterable</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.PredictionResult" title="apache_beam.ml.inference.base.PredictionResult"><span class="pre">PredictionResult</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFacePipelineModelHandler.run_inference"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.run_inference" title="Link to this definition">Â¶</a></dt>
<dd><p>Runs inferences on a batch of examples passed as a string resource.
These can either be string sentences, or string path to images or
audio files.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> â A sequence of strings resources.</p></li>
<li><p><strong>pipeline</strong> â A Hugging Face Pipeline.</p></li>
<li><p><strong>inference_args</strong> â Non-batchable arguments required as inputs to the modelâs
inference function.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An Iterable of type PredictionResult.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.update_model_path">
<span class="sig-name descname"><span class="pre">update_model_path</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFacePipelineModelHandler.update_model_path"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.update_model_path" title="Link to this definition">Â¶</a></dt>
<dd><p>Updates the pretrained model used by the Hugging Face Pipeline task.
Make sure that the new model does the same task as initial model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) â (Optional) Path to the new trained model
from Hugging Face. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.get_num_bytes">
<span class="sig-name descname"><span class="pre">get_num_bytes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(in Python v3.13)"><span class="pre">Sequence</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFacePipelineModelHandler.get_num_bytes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.get_num_bytes" title="Link to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The number of bytes of input batch elements.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.batch_elements_kwargs">
<span class="sig-name descname"><span class="pre">batch_elements_kwargs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFacePipelineModelHandler.batch_elements_kwargs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.batch_elements_kwargs" title="Link to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.share_model_across_processes">
<span class="sig-name descname"><span class="pre">share_model_across_processes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFacePipelineModelHandler.share_model_across_processes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.share_model_across_processes" title="Link to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.model_copies">
<span class="sig-name descname"><span class="pre">model_copies</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFacePipelineModelHandler.model_copies"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.model_copies" title="Link to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.get_metrics_namespace">
<span class="sig-name descname"><span class="pre">get_metrics_namespace</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></span><a class="reference internal" href="_modules/apache_beam/ml/inference/huggingface_inference.html#HuggingFacePipelineModelHandler.get_metrics_namespace"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apache_beam.ml.inference.huggingface_inference.HuggingFacePipelineModelHandler.get_metrics_namespace" title="Link to this definition">Â¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A namespace for metrics collected by the RunInference transform.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="apache_beam.ml.inference.base.html" class="btn btn-neutral float-left" title="apache_beam.ml.inference.base module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="apache_beam.ml.inference.onnx_inference.html" class="btn btn-neutral float-right" title="apache_beam.ml.inference.onnx_inference module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>